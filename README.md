# ğŸ§  AI Experiments - AI Playgorund

> A playground for building and testing ideas with AI
> Each project lives in its own folder with all details inside.

## ğŸ“‚ Projects

---

### ğŸ“ **MCPGraph**

A LLM-powered backend for building and interpreting user-specific knowledge graphs.  
It uses **FastMCP** for dynamic tool orchestration and **Neo4j** for graph-based memory and reasoning.

This project enables natural language queries to be transformed into structured graph data using simulated web search,
concept extraction, reranking, and automatic linking via Neo4j GDS.

ğŸ” The pipeline includes:

1. Simulated search (via LLM)
2. Concept extraction + deduplication
3. Graph storage (`REMEMBERS`)
4. GDS similarity linking (`RELATED_TO`)
5. Graph querying + reranking
6. Summary response generation

ğŸ§© Each step is a modular **MCP tool**, allowing composable reasoning and API access (e.g. `fullPipeline`, `explain_graph`, `search://`, `concept://`).

âš™ï¸ Tech used: FastMCP, Neo4j (GDS), LangChain, OpenAI or Gemini, Python 3.10+

---

### ğŸ“ **neo4j** â€“ Hybrid Graph + Embedding RAG Demo

ğŸš€ A proof-of-concept that blends **Neo4j graph relationships** and **vector search** to power a Retrieval-Augmented Generation (RAG) system using **Google Gemini**.
It ingests structured â€œDoctor Whoâ€ data into a `Book â†’ Chapter â†’ Section â†’ Text` graph, builds both **vector** and **graph** indexes, then performs **hybrid search** to answer user questions contextually.

ğŸ§° Tech used: Docker, Python, Neo4j, Sentence-Transformers, LangChain, Gemini
ğŸ“ Scripts:

* `createVectorIndex.py` â€“ Creates a vector index
* `generateEmbeddings.py` â€“ Embeds raw text
* `queryGraphWithEmbedding.py` â€“ Query via embedding
* `createEmbedingsGraphsMetadataRelationships.py` â€“ Full ingestion & indexing
* `hybridVsGraphVsVector.py` â€“ Compare search modes
* `ragAnswerGenerator.py` â€“ RAG via LangChain & Gemini

---

### ğŸ“ **voice-io-lang-graph** â€“ Multi-Agent Voice Chat with LangGraph, Gemini & ElevenLabs

ğŸ—£ï¸ A voice-enabled terminal chatbot where you interact with four chaotic AI personasâ€”**Rick**, **Morty**, **Jerry**, and **Golubiro**, a paranoid drone-pigeon spy. 

Uses **Google Gemini** for natural language and **ElevenLabs** for speech.

ğŸ§  Orchestrated with **LangGraph** as a declarative state machine:

1. You talk (via microphone or type).
2. LangGraph routes your message to the most relevant character using LLM-based classification.
3. The character responds.
4. If the character was Rick or Morty, a follow-up response is triggered by Golubiro or Jerry.
5. The flow loops back to capture the next input.

ğŸ§° Tech used: LangGraph, LangChain, Google Gemini (`langchain_google_genai`), ElevenLabs TTS, `speech_recognition`, Python 3.10+

---
