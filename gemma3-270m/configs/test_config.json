{
  "model": {
    "name": "gemma3-270m",
    "path": "./models",
    "max_length": 1024,
    "vocab_size": 262144
  },
  "training": {
    "batch_size": 4,
    "gradient_accumulation_steps": 1,
    "effective_batch_size": 4,
    "learning_rate": 0.0001,
    "warmup_steps": 10,
    "max_steps": 10,
    "save_steps": 5,
    "eval_steps": 5,
    "logging_steps": 1,
    "max_grad_norm": 1.0,
    "weight_decay": 0.01,
    "lr_scheduler_type": "cosine",
    "num_train_epochs": 1
  },
  "lora": {
    "enabled": true,
    "rank": 4,
    "alpha": 8,
    "dropout": 0.1,
    "target_modules": [
      "q_proj",
      "v_proj",
      "k_proj"
    ]
  },
  "data": {
    "train_file": "./data/train.jsonl",
    "validation_file": "./data/validation.jsonl",
    "test_file": "./data/test.jsonl",
    "text_column": "text",
    "label_column": "label",
    "max_seq_length": 512,
    "streaming": false,
    "shuffle_buffer_size": 100
  },
  "optimization": {
    "mixed_precision": "bf16",
    "gradient_checkpointing": false,
    "dataloader_num_workers": 1,
    "dataloader_pin_memory": false
  },
  "evaluation": {
    "metrics": [
      "accuracy"
    ],
    "mteb_tasks": [
      "text-classification"
    ],
    "eval_batch_size": 4
  },
  "output": {
    "output_dir": "./outputs/test",
    "save_total_limit": 1,
    "overwrite_output_dir": true,
    "push_to_hub": false
  },
  "logging": {
    "log_level": "info",
    "log_file": "./logs/test_training.log",
    "tensorboard_log_dir": "./logs/tensorboard"
  },
  "hardware": {
    "device": "auto",
    "max_memory": "8GB",
    "num_gpus": 1
  }
}